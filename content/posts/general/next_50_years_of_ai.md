---
title: "Next 50 Years of AI"
date: 2026-01-23T00:00:00Z
description: Over the last 6 months, AI adoption was exponential, but is it really all that useful? Will AI take more jobs?
tags:
  - general
  - AI
categories:
  - General
draft: false
---

## So

Let's face the facts, AI already changed the way most programmers work. It did replace Stackoverflow, some non-niche programming forums, and even googling for some of us. What's next? Will it continue developing with that pace? What will the future look like in 1, 10, or 50 years from now?

Obviously, I have no idea, but let's guess. Let's assume the pace keeps up. What's next?

## Present - Jan 18, 2026

### Coding

- **Code management** - it can replace routine code management work with 95%+ accuracy. If we rely on compilation tools and tests to detect errors and hallucinations - this is an amazing tool.
- **New code - PoC** - it's very good at building PoC to verify the concept against your own vision or even market. It's not capable of making it reliable though, but it's pretty decent at building it _as you told it to_. It's capable of thinking of _some_ edge cases you haven't thought of (or haven't prompted), but it's far away from building robust and reliable software that's more complex than a todo app.
  Although, I'm not sure it's capable of building a robust todo app either. It needs to be overseen with caution, but after some re-prompting it can get almost anything done. It really speeds up the development process by a ton, but changes _the way_ you program.
- **New, production-ready code** - not yet. The solutions it proposes are far away from maintainable ones. But someone inexperienced might not be able to accomplish anything close at all, so it _might_ be _some_ starting point for many.
- **Existing code** - good at following pre-existing patterns, bad at coming up with new, reliable ones. Can make something _look like_ it's working, but appear crap after thorough revision. Could trick inexperienced devs into thinking it's capable of building **_good_ software**, whereas it's not.

**Building software became cheaper. Building good software became more expensive.**

### Web research

This is more and more of a problem, since it's abnormally hard to find good products on the internet now. Everyone is buying reviews, everyone is buying fake comments, bots are everywhere, and it's close to impossible to distinguish truth from fake. And it'll become even worse with time.

For now, agents in deep research mode are pretty capable in terms of scraping reddit comments or product review pages and generalizing the opinions there. But I expect this particular thing to only worsen with time. [Dead Internet theory - Wikipedia](https://en.wikipedia.org/wiki/Dead_Internet_theory) is not a joke, and I really think it'll be a reality in a few.

But for now, the internet has more real users than bots (I think), and it's _manageable_ to be there. Though I'm not leaving comments nor reactions. I don't like the idea to sell my interests for some model to be trained on in the future, so that I could have _ultra_ personalized recommendations.
LLMs don't have ads for now, but [OpenAI announced ads](https://openai.com/index/our-approach-to-advertising-and-expanding-access/) some time ago, and this trajectory is thrilling. For now, without ads, the experience in picking the best tool is amazing. Researching things and topics works really good.

### Automation

Agents are not yet there, most frameworks utilize Prompt - Action - Prompt model, which I think is pretty limiting.

### Taking other jobs

- For now, most affected jobs are text writers, or, in general, people who relied on outputting non-artistic text for a living.
- Programmers are affected in a way that less jobs are open in the market too, though AI-driven layoffs are accelerating.

## In a year, Jan 18, 2027

The main change in a year would be monetizing the LLMs. We'll see ads in every (or most) LLM providers, ads will become more and more intrusive. Products, services, political movements, everything will be advertised, and we, users, will be sold. For free tiers - ads will be everywhere, paid plans will see only a small touch of ads, but that will become worse with time.

Coding models will not improve widely, we'll see some unnoticeable bumps, but it'll remain clear that LLMs can't produce reliable software _yet_. So building good software is still very expensive.

Medical usage will not surge, people would still mostly rely on real doctors for healthcare.

## In 10 years, Jan 18, 2036

I assume that the only way to progress with the same rate is to change the way LLMs work. In 10 years, I expect us to teach models to learn. I won't call it AGI yet, but they'll be able to **absorb** _some limited_ knowledge. This will allow them to learn on their mistakes, and develop some intelligence in our sense.

**Programming** will look entirely different, codebases will be AI-first, humans without AI won't be able to operate a codebase. All changes will be made in some way via LLMs, and this will be the new standard way of communication. Your personal LLM will be integrated with everything, and you'll use it as an interface to all other applications. You'll ask it to order Uber for you, get groceries handled, plans, money, everything. Every major site will be LLM-friendly.

**Frameworks** like [Legion](https://github.com/dimamik/legion) will take over, LLM will generate code to orchestrate itself. It'll become clear that precision and accuracy is the new trend. Tests will be at entirely new level, where LLMs will verify themselves, do peer reviews, and learn on the mistakes.
We won't be able to hit AGI just yet, because the learning abilities will be very limited, but countries' economies will be put at stake, and most of people believe it'll be possible

**Automation** won't be achieved quite yet, since LLMs are unpredictable, they'll still be operated by people.

**Internet** will slowly become a worse place to be. Bots will be indistinguishable from humans, and interacting there will be painful. More intellect will go to streets to communicate. Humanity will slowly enter the era of post-internet, where people prefer phone calls over messages, going out over sitting at home.

Average **person** will know and remember less, due to the nature of information acquisition. It will take 5 seconds to learn anything, so nothing will stick. The curiosity of people will become a new society problem.

**Medicine** will be transformed to LLM-first. Medium class people will be triaged by LLMs, which will help reduce medical care load, but ethics of these decisions will be questioned by some society groups. Robotic diagnosis will catch 800% more cases than previous screenings.

**Blood taking labs** will see enormous profits from newcomers at self-diagnostics.

**LLM psychology** will be a new trend, and it'll really help lonely and suicidal people.
Building **good software** is still a problem. Software engineers with experience of building reliable systems are extremely valuable.

## In 50 years, Jan 18, 2076

A big **medicine** step forward, mostly due to more accessible information will lead to the growing popularity of wearable devices. They'll take your blood samples realtime and will detect diseases and changes in blood cell levels, to prevent health conditions at _very_ early stages.

**AI-driven robots** will help people in their homes, and will become more and more common.
Labour we see today will be reshaped. White-suits will earn less than blue-collars now, due to the nature of their work. LLM will become a part of every workflow, same as computers now. **Housing** will be more affordable than now due to population decline, but the average life quality will decrease. The **air pollution** will become a real problem, even though all energy will come from renewable sources.

# Well

I have no idea if any of the things I wrote here make sense. Let me know what do you think!
